{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import os.path as osp\n",
    "import glob\n",
    "from skimage.transform import rescale, resize\n",
    "from skimage.io import imsave, imread\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceLandmarksDataset():\n",
    "    def __init__(self, root_dir, model_type=\"recognition\", transform=None):\n",
    "        self.data_list = glob.glob(osp.join(root_dir, '*.jpg'))\n",
    "        labels = []\n",
    "        for d in self.data_list:\n",
    "            data = d.split(\"/\")\n",
    "            data = data[2].split(\"_\")\n",
    "            labels.append(data[0])\n",
    "        self.labels = labels\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        image = self.data_list[idx]\n",
    "        \n",
    "        # Image\n",
    "        img = imread(image)\n",
    "        img1 = resize(img, (224,224,3))\n",
    "        image = torch.from_numpy(img1)\n",
    "        # One Hot Labels\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        for i in range(11):\n",
    "            if int(label) == i:\n",
    "                gt_label = i\n",
    "\n",
    "        \n",
    "        # Sample\n",
    "        sample = {'image': image, 'gt_label': gt_label}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "Face_train = FaceLandmarksDataset(root_dir='./train_images/')\n",
    "\n",
    "train_loader = DataLoader(Face_train, batch_size=1,\n",
    "                        shuffle=False, num_workers=1)\n",
    "\n",
    "Face_val = FaceLandmarksDataset(root_dir='./val_images/')\n",
    "val_loader = DataLoader(Face_val, batch_size=1,\n",
    "                        shuffle=False, num_workers=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.layer_d0 = nn.Sequential(nn.Conv2d(3, 8, 7, padding=3, stride=1, bias=True),nn.ReLU())\n",
    "\n",
    "        \n",
    "        self.layer_d1 = nn.Sequential(nn.Conv2d(8, 16, 3, padding=1, stride=2, bias=True),\n",
    "                                      nn.ReLU(), nn.Conv2d(16, 16, 3, padding=1, stride=1, bias=True))\n",
    "        self.layer_d1s = nn.Conv2d(8, 16, 1, stride=2)\n",
    "        self.relu_d1 = nn.ReLU()\n",
    "\n",
    "        \n",
    "        self.layer_d2 = nn.Sequential(nn.Conv2d(16, 32, 3, padding=1, stride=2, bias=True),\n",
    "                                      nn.ReLU(), nn.Conv2d(32, 32, 3, padding=1, stride=1, bias=True))\n",
    "        self.layer_d2s = nn.Conv2d(16, 32, 1, stride=2)\n",
    "        self.relu_d2 = nn.ReLU()\n",
    "\n",
    "\n",
    "        self.layer_d3 = nn.Sequential(nn.Conv2d(32, 64, 3, padding=1, stride=2, bias=True),\n",
    "                                      nn.ReLU(), nn.Conv2d(64, 64, 3, padding=1, stride=1, bias=True))\n",
    "        self.layer_d3s = nn.Conv2d(32, 64, 1, stride=2)\n",
    "        self.relu_d3 = nn.ReLU()\n",
    "\n",
    "        \n",
    "#         self.layer_d4 = nn.Sequential(nn.Conv2d(64, 128, 3, padding=1, stride=2, bias=True),\n",
    "#                                       nn.ReLU(), nn.Conv2d(128, 128, 3, padding=1, stride=1, bias=True))\n",
    "#         self.layer_d4s = nn.Conv2d(64, 128, 1, stride=2)\n",
    "#         self.relu_d4 = nn.ReLU()\n",
    "        \n",
    "        self.layer200 = nn.AvgPool2d(32,32)\n",
    "\n",
    "        self.layer201 = nn.Sequential(nn.Linear(64, 11, bias=True))\n",
    "\n",
    "    def forward(self, input_img):\n",
    "\n",
    "        output = self.layer_d0(input_img)\n",
    "\n",
    "        output_d1 = self.layer_d1(output)\n",
    "        output_d1s = self.layer_d1s(output)\n",
    "        output = output_d1 + output_d1s\n",
    "        output = self.relu_d1(output)\n",
    "\n",
    "        output_d2 = self.layer_d2(output)\n",
    "        output_d2s = self.layer_d2s(output)\n",
    "        output = output_d2 + output_d2s\n",
    "        output = self.relu_d2(output)\n",
    "\n",
    "        output_d3 = self.layer_d3(output)\n",
    "        output_d3s = self.layer_d3s(output)\n",
    "        output = output_d3 + output_d3s\n",
    "        output = self.relu_d3(output)\n",
    "\n",
    "#         output_d4 = self.layer_d4(output)\n",
    "#         output_d4s = self.layer_d4s(output)\n",
    "#         output = output_d4 + output_d4s\n",
    "#         output = self.relu_d4(output)\n",
    "        \n",
    "        df4  = output\n",
    "        \n",
    "        gap_feats = self.layer200(output)\n",
    "        gap_feats = gap_feats.view(gap_feats.shape[0], -1)\n",
    "        probs = self.layer201(gap_feats)\n",
    "        \n",
    " \n",
    "#         df4 = torch.cat((df4),1)\n",
    "\n",
    "\n",
    "        return probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Trainer(object):\n",
    "    def __init__(self):\n",
    "        self.global_step = 0\n",
    "        self.epoch = 0\n",
    "        \n",
    "        self.model = Model()\n",
    "#         print(\"ckcnlkcnkcs\",self.model)\n",
    "#         if torch.cuda.device_count() > 1:\n",
    "#             print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "#             # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "#             device_ids = [i for i in range(torch.cuda.device_count())]\n",
    "#             self.model = nn.DataParallel(self.model, device_ids)\n",
    "\n",
    "        print(self.model)\n",
    "        self.model.to(device)\n",
    "        \n",
    "        self.class_loss_fn1 = nn.CrossEntropyLoss()\n",
    "\n",
    "        # OPTIMIZER\n",
    "        no_wd = []\n",
    "        wd = []\n",
    "        print('Weight Decay applied to: ')\n",
    "\n",
    "\n",
    "\n",
    "        for name, p in self.model.named_parameters():\n",
    "            if not p.requires_grad:\n",
    "                # No optimization for frozen params\n",
    "                continue\n",
    "\n",
    "            if 'bn' in name or 'bias' in name:\n",
    "                no_wd.append(p)\n",
    "            else:\n",
    "                wd.append(p)\n",
    "                print(name,)\n",
    "\n",
    "\n",
    "\n",
    "        # Allow individual options\n",
    "        self.optimizer = optim.Adam(\n",
    "            [\n",
    "                {'params': no_wd, 'weight_decay': 0.0},\n",
    "                {'params': wd}\n",
    "            ],\n",
    "            lr= 2e-5,\n",
    "            weight_decay=1e-5,\n",
    "            amsgrad=False)\n",
    "\n",
    "        self.lr_decay = optim.lr_scheduler.StepLR(self.optimizer, step_size=2,\n",
    "                                                  gamma=0.1)\n",
    "\n",
    "    def save_checkpoint(self, epoch):\n",
    "        save_state = {\n",
    "            'epoch': epoch,\n",
    "            'global_step': self.global_step,\n",
    "            'gcn_state_dict': self.model.state_dict(),\n",
    "            'optimizer': self.optimizer.state_dict(),\n",
    "            'lr_decay': self.lr_decay.state_dict()\n",
    "        }\n",
    "\n",
    "        save_name = os.path.join(\"./\", 'checkpoints', 'epoch_plostp_%d_step%d.pth' \\\n",
    "                                 % (epoch, self.global_step))\n",
    "        torch.save(save_state, save_name)\n",
    "        print('Saved model')\n",
    "\n",
    "\n",
    "    def loop(self):\n",
    "        for epoch in range(self.epoch,100):\n",
    "            self.epoch = epoch\n",
    "            if self.epoch % 3 == 0 and self.epoch > 0:\n",
    "                self.save_checkpoint(epoch)\n",
    "            if self.epoch >= 90:\n",
    "                break\n",
    "            self.train(epoch)\n",
    "            self.validate(epoch)\n",
    "\n",
    "    def train(self, epoch):\n",
    "        print('Starting training')\n",
    "        self.model.train()\n",
    "        losses = []\n",
    "        accum = defaultdict(float)\n",
    "        \n",
    "        for step, data in enumerate(train_loader):\n",
    "\n",
    "            img = data['image']\n",
    "#             print(img)\n",
    "#             img = torch.cat(img)\n",
    "            img = img.view(-1, 224, 224, 3)\n",
    "            img = torch.transpose(img, 1, 3)\n",
    "            img = torch.transpose(img, 2, 3)\n",
    "            img = img.float()\n",
    "            \n",
    "            gt_label = torch.tensor(data[\"gt_label\"])\n",
    "            \n",
    "            probs = self.model(img.to(device))\n",
    "            \n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            class_loss = self.class_loss_fn1(probs, gt_label.to(device))\n",
    "            \n",
    "            loss_v = class_loss\n",
    "            loss1 = class_loss\n",
    "            loss_v.backward()\n",
    "            \n",
    "            self.optimizer.step()\n",
    "            \n",
    "            losses.append(loss1)\n",
    "\n",
    "        avg_epoch_loss = 0.0\n",
    "        for i in range(len(losses)):\n",
    "            avg_epoch_loss += losses[i]\n",
    "\n",
    "        avg_epoch_loss = avg_epoch_loss / len(losses)\n",
    "        self.gcn_loss_sum_train = avg_epoch_loss\n",
    "\n",
    "        print(\"Average Epoch %d loss is : %f\" % (epoch, avg_epoch_loss))\n",
    "        \n",
    "    def validate(self,epoch):\n",
    "        print('Validating')\n",
    "        self.model.eval()\n",
    "        losses = []\n",
    "        with torch.no_grad():\n",
    "            for step, data in enumerate(val_loader):\n",
    "                img = data['image']\n",
    "                img = img.view(-1, 224, 224, 3)\n",
    "                img = torch.transpose(img, 1, 3)\n",
    "                img = torch.transpose(img, 2, 3)\n",
    "                img = img.float()\n",
    "                \n",
    "                gt_label = torch.tensor(data[\"gt_label\"])\n",
    "            \n",
    "                probs = self.model(img.to(device))\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "            \n",
    "                class_loss = self.class_loss_fn1(probs, gt_label.to(device))\n",
    "\n",
    "                loss = class_loss\n",
    "                losses.append(loss)\n",
    "            \n",
    "            avg_epoch_loss = 0.0\n",
    "            for i in range(len(losses)):\n",
    "                avg_epoch_loss += losses[i]\n",
    "\n",
    "            avg_epoch_loss = avg_epoch_loss / len(losses)\n",
    "            self.gcn_loss_sum_train = avg_epoch_loss\n",
    "\n",
    "            print(\"Average Epoch %d Validation loss is : %f\" % (epoch, avg_epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (layer_d0): Sequential(\n",
      "    (0): Conv2d(3, 8, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (layer_d1): Sequential(\n",
      "    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (layer_d1s): Conv2d(8, 16, kernel_size=(1, 1), stride=(2, 2))\n",
      "  (relu_d1): ReLU()\n",
      "  (layer_d2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (layer_d2s): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
      "  (relu_d2): ReLU()\n",
      "  (layer_d3): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (layer_d3s): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
      "  (relu_d3): ReLU()\n",
      "  (layer200): AvgPool2d(kernel_size=32, stride=32, padding=0)\n",
      "  (layer201): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=11, bias=True)\n",
      "  )\n",
      ")\n",
      "Weight Decay applied to: \n",
      "layer_d0.0.weight\n",
      "layer_d1.0.weight\n",
      "layer_d1.2.weight\n",
      "layer_d1s.weight\n",
      "layer_d2.0.weight\n",
      "layer_d2.2.weight\n",
      "layer_d2s.weight\n",
      "layer_d3.0.weight\n",
      "layer_d3.2.weight\n",
      "layer_d3s.weight\n",
      "layer201.0.weight\n",
      "Starting training\n",
      "Average Epoch 0 loss is : 2.400373\n",
      "Validating\n",
      "Average Epoch 0 Validation loss is : 2.399058\n",
      "Starting training\n",
      "Average Epoch 1 loss is : 2.391048\n",
      "Validating\n",
      "Average Epoch 1 Validation loss is : 2.397889\n",
      "Starting training\n",
      "Average Epoch 2 loss is : 2.379466\n",
      "Validating\n",
      "Average Epoch 2 Validation loss is : 2.397657\n",
      "Saved model\n",
      "Starting training\n",
      "Average Epoch 3 loss is : 2.366397\n",
      "Validating\n",
      "Average Epoch 3 Validation loss is : 2.398689\n",
      "Starting training\n",
      "Average Epoch 4 loss is : 2.353872\n",
      "Validating\n",
      "Average Epoch 4 Validation loss is : 2.395480\n",
      "Starting training\n",
      "Average Epoch 5 loss is : 2.340108\n",
      "Validating\n",
      "Average Epoch 5 Validation loss is : 2.386478\n",
      "Saved model\n",
      "Starting training\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer()\n",
    "trainer.loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target):\n",
    "    global batch_size\n",
    "    correct = 0\n",
    "    for i in range(output.shape[0]):\n",
    "        if output[i][1] >= 0.5:\n",
    "            if target[i] == 1:\n",
    "                correct += 1\n",
    "        else:\n",
    "            if target[i] == 0:\n",
    "                correct += 1\n",
    "    return correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
